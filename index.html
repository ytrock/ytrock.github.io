<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Tao Yu's Homepage</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom fonts for this template -->
    <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:100,200,300,400,500,600,700,800,900" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i,800,800i" rel="stylesheet">
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet">
    <link href="vendor/devicons/css/devicons.min.css" rel="stylesheet">
    <link href="vendor/simple-line-icons/css/simple-line-icons.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="css/resume.css" rel="stylesheet">

  </head>

  <body id="page-top">

    <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
      <a class="navbar-brand js-scroll-trigger" href="#page-top">
        <span class="d-block d-lg-none">Tao Yu</span>
        <span class="d-none d-lg-block">
          <img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="./img/YT.jpg" alt="">
        </span>
      </a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav">
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#about">About</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#publication">Publication</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#experience">Experience</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#skills">Skills</a>
          </li>
        </ul>
      </div>
    </nav>

    <div class="container-fluid p-0">

      <section class="resume-section p-3 p-lg-5 d-flex d-column" id="about">
        <div class="my-auto">
          <h1 class="mb-0">
            <span class="text-primary"></span>Tao Yu</span>
          </h1>
          <h2>于涛</h2>
          <div class="subheading mb-5">Room 817B, Central Main Building, Tsinghua University, Beijing, China, 100084·
            <a href="mailto:ytrock@126.com">ytrock@126.com</a>
          </div>
          <p class="mb-5">Hi, I am a 4th year PhD Candidate at Beihang University, my supervisor is Prof. Jianhui Zhao. <br>I also work closely with <a href="http://www.liuyebin.com">Prof. Yebin Liu</a> at Tsinghua University since 2014.</p>
          <p class="mb-5">My research area is Computer Vision and Computer Graphics. <br>Specifically, I'm working on Real-time Dynamic 3D Reconstruciton Algorithms for Human Performance Capture.</p><br>My goal is to enable <b>convenient</b> & <b>robust</b> & <b>high quality</b> performance capture for everyone. 
        </div>
      </section>
    </div>
      
      <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="publication">
          <h2 class="mb-5">Publication</h2>

            <div class="project">
              <div class="project-image">
                <br>
                <img src="img/deepHuman.jpg" width="250px" height="150px"/>
              </div>
              <!-- End .project-image -->
              <div class="project-info">
                  <h3>DeepHuman: 3D Human Reconstruction from a Single Image</h3>
                  <p>
                    <a href="https://zhengzerong.github.io/">Zerong Zheng</a>, <b>Tao Yu</b>, Yixuan Wei, <a href="http://media.au.tsinghua.edu.cn/qhdai.html">Qionghai Dai</a>, <a href="http://www.liuyebin.com">Yebin Liu</a>
                  </p>
                  <p style="color: #EF7F27;">
                    <b>Arxiv 2019</b>
                  </p>
                  <p>
                    We propose DeepHuman, a deep learning based framework for 3D human reconstruction from a single RGB image. Since this problem is highly intractable, we adopt a stage-wise, coarse-to-fine method consisting of three steps, namely inner body estimation, outer surface reconstruction and frontal surface detail refinement. 
                  </p>
                  <p>
                      <a href="http://www.liuyebin.com/deephuman/deephuman.html">[Webpage]</a>&nbsp;
                      <a href="https://arxiv.org/abs/1903.06473">[Arxiv]</a>&nbsp;
                      <a href="http://www.liuyebin.com/deephuman/assets/DeepHumanReduced.mp4">[Video]</a>&nbsp;
                  </p>
              </div>
              <!-- End .project-info -->
            </div>
            <br><br>

            <div class="project">
              <div class="project-image">
                <br>
                <img src="img/ufusion.jpg" width="250px" height="150px"/>
              </div>
              <!-- End .project-image -->
              <div class="project-info">
                  <h3>UnstructuredFusion: Real-time 4D Geometry and Texture Reconstruction using Commercial RGBD Cameras</h3>
                  <p>
                    <a href="https://xulan.github.io/">Lan Xu</a>, Zhuo Su, Lei Han, <b>Tao Yu</b>, <a href="http://www.liuyebin.com">Yebin Liu</a>, <a href="http://www.luvision.net/">Lu Fang</a>
                  </p>
                  <p style="color: #EF7F27;">
                    IEEE Transactions on Pattern Analysis and Machine Intelligence <b>(TPAMI 2019)</b>
                  </p>
                  <p>
                    In this paper, we propose UnstructuredFusion, a practicable realtime markerless human performance capture method using unstructured commercial RGBD cameras. Along with the flexible hardware setup using simply three unstructured RGBD cameras without any careful pre-calibration, the challenge 4D reconstruction through multiple asynchronous videos is solved by proposing three novel technique contributions, i.e., online multi-camera calibration, skeleton warping based non-rigid tracking, and temporal blending based atlas texturing. 
                  </p>
                  <p>
                      <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8708933">[Paper]</a>&nbsp;
                      <a href="https://youtu.be/jnLyQ5-ni-0">[Youtube]</a>&nbsp;
                  </p>
              </div>
              <!-- End .project-info -->
            </div>
            <br><br>

            <div class="project">
              <div class="project-image">
                <br>
                <img src="img/simulCap.png" width="250px" height="150px"/>
              </div>
              <!-- End .project-image -->
              <div class="project-info">
                  <h3>SimulCap: Single-View Human Performance Capture with Cloth Simulation</h3>
                  <p>
                    <b>Tao Yu</b>, <a href="https://zhengzerong.github.io/">Zerong Zheng</a>, Yuan Zhong, Jianhui Zhao, <a href="http://media.au.tsinghua.edu.cn/qhdai.html">Qionghai Dai</a>, <a href="http://virtualhumans.mpi-inf.mpg.de/">Gerard Pons-Moll</a>, <a href="http://www.liuyebin.com">Yebin Liu</a>
                  </p>
                  <p style="color: #EF7F27;">
                    IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR 2019)</b>
                  </p>
                  <p>
                    This paper proposes a new method for live free-viewpoint human performance capture with dynamic details (e.g., cloth wrinkles) using a single RGBD camera. Our main contributions are: (i) a multi-layer representation of garments and body, and (ii) a physics-based performance capture procedure. 
                  </p>
                  <p>
                      <a href="http://www.liuyebin.com/simulcap/simulcap.html">[Webpage]</a>&nbsp;
                      <a href="https://arxiv.org/abs/1903.06323">[Arxiv]</a>&nbsp;
                      <a href="https://www.youtube.com/watch?v=rTdz3saGKsQ">[Youtube]</a>
                      <a href="http://www.liuyebin.com/simulcap/assets/2455_SimulCap_Video_Sub_Refined_2.mp4">[Video]</a>&nbsp;
                  </p>
              </div>
              <!-- End .project-info -->
            </div>
            <br><br>

            <div class="project">
              <div class="project-image">
                <br>
                <img src="img/hybfu.jpg" width="250px" height="150px"/>
              </div>
              <!-- End .project-image -->
              <div class="project-info">
                  <h3>HybridFusion: Real-time Performance Capture Using a Single Depth Sensor and Sparse IMUs</h3>
                  <p>
                    <a href="https://zhengzerong.github.io/">Zerong Zheng</a>, <b>Tao Yu</b>, <a href = "http://hao-li.com/Hao_Li/Hao_Li_-_about_me.html">Hao Li</a>, <a href="http://guokaiwen.com/">Kaiwen Guo</a>, <a href="http://media.au.tsinghua.edu.cn/qhdai.html">Qionghai Dai</a>, <a href="http://www.luvision.net/">Lu Fang</a>, <a href="http://www.liuyebin.com">Yebin Liu</a>
                  </p>
                  <p style="color: #EF7F27;">
                    European Conference on Computer Vision <b>(ECCV 2018)</b>
                  </p>
                  <p>
                    We propose a light-weight and highly robust real-time human performance capture method based on hybrid depth&IMU sensors. The method can reconstruct challenging motions, detailed geometries and the inner human body shapes of a clothed subject simultaneously in real-time. 
                  </p>
                  <p>
                      <a href="http://www.liuyebin.com/hybridfusion/hybridfusion.html">[Webpage]</a>&nbsp;
                      <a href="http://www.liuyebin.com/hybridfusion/hybridfusion.pdf">[Paper]</a>&nbsp;
                      <a href="https://www.youtube.com/watch?v=kea2msa52yY">[Youtube]</a>
                      <a href="http://www.liuyebin.com/hybridfusion/hybridfusion.mp4">[Video]</a>&nbsp;
                  </p>
              </div>
              <!-- End .project-info -->
            </div>
            <br><br>

            <div class="project">
              <div class="project-image">
                <br>
                <img src="img/dblfu.png" width="250px" height="150px"/>
              </div>
              <!-- End .project-image -->
              <div class="project-info">
                <h3>DoubleFusion: Real-time Capture of Human Performances with Inner Body Shapes from a Single Depth Sensor</h3>
                <p>
                  <b>Tao Yu</b>, <a href="https://zhengzerong.github.io/">Zerong Zheng</a>, <a href="http://guokaiwen.com/">Kaiwen Guo</a>, Jianhui Zhao, <a href="http://media.au.tsinghua.edu.cn/qhdai.html">Qionghai Dai</a>, <a href = "http://hao-li.com/Hao_Li/Hao_Li_-_about_me.html">Hao Li</a>, <a href="http://virtualhumans.mpi-inf.mpg.de/">Gerard Pons-Moll</a>, <a href="http://www.liuyebin.com">Yebin Liu</a>
                </p>
                <p style="color: #EF7F27;">
                  IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR 2018 Oral Presentation)</b>
                </p>
                <p>
                  We propose DoubleFusion, a new real-time system that combines volumetric dynamic reconstruction with datadriven template ﬁtting to simultaneously reconstruct detailed geometry, non-rigid motion and the inner human body shape from a single depth camera.
                </p>
                <p>
                  <a href="http://www.liuyebin.com/doublefusion/doublefusion.htm">[Webpage]</a>&nbsp;
                  <a href="https://arxiv.org/abs/1804.06023">[Arxiv]</a>
                  <a href="http://www.liuyebin.com/doublefusion/doublefusion_files/doublefusion.pdf">[Paper]</a>&nbsp;
                  <a href="https://www.youtube.com/watch?v=23LMfj2soNQ&t=4s">[Youtube]</a>
                  <a href="http://www.liuyebin.com/doublefusion/doublefusion_files/DoubleFusion_SupVideo_CameraReady.mp4">[Video]</a>&nbsp;
                  <a href="https://techcrunch.com/2018/06/18/whats-under-those-clothes-this-system-tracks-body-shapes-in-real-time/">[TechCrunch]</a>
                  <a href="https://www.sohu.com/a/236837949_395737">[Sohu]</a>&nbsp;
                </p>
              </div>
              <!-- End .project-info -->
            </div>
            <br><br>
            
            <div class="project">
              <div class="project-image">
                <br>
                <img src="img/bdyfu.jpg" width="250px" height="150px"/>
              </div>
              <!-- End .project-image -->
              <div class="project-info">
                <h3>BodyFusion: Real-time Capture of Human Motion and Surface Geometry Using a Single Depth Camera</h3>
                <p>
                  <b>Tao Yu</b>, <a href="http://guokaiwen.com/">Kaiwen Guo</a>, <a href="http://feng-xu.com/">Feng Xu</a>, Yuan Dong, Zhaoqi Su, Jianhui Zhao, Jianguo Li, <a href="http://media.au.tsinghua.edu.cn/qhdai.html">Qionghai Dai</a>, <a href="http://www.liuyebin.com">Yebin Liu</a>
                </p>
                <p style="color: #EF7F27;">
                  IEEE International Conference on Computer Vision <b>(ICCV 2017)</b>
                </p>
                <p>
                  We propose BodyFusion, a novel real-time geometry fusion method that can track and reconstruct non-rigid surface motion of a human performance using a single consumer-grade depth camera. 
                </p>
                <p>
                  <a href="http://liuyebin.com/bodyfusion/bodyfusion.htm">[Webpage]</a>&nbsp;
                  <a href="http://liuyebin.com/bodyfusion/bodyfusion_files/BdyFu_ICCV17.pdf">[Paper]</a>&nbsp;
                  <a href="https://youtu.be/tyIWois6sRc">[Youtube]</a>
                  <a href="http://liuyebin.com/bodyfusion/bodyfusion_files/BodyFusion_SupVideo_CameraReady.mp4">[Video]</a>&nbsp;
                </p>
              </div>
              <!-- End .project-info -->
            </div>
            <br><br>
      
            <div class="project">
              <div class="project-image">
                <br>
                <img src="img/albedofu.jpg" width="250px" height="150px"/>
              </div>
              <!-- End .project-image -->
              <div class="project-info">
                <h3>Real-time Geometry, Albedo and Motion Reconstruction Using a Single RGBD Camera</h3>
                <p>
                  <a href="http://guokaiwen.com/">Kaiwen Guo</a>, <a href="http://feng-xu.com/">Feng Xu</a>, <b>Tao Yu</b>, Xiaoyang Liu, <a href="http://media.au.tsinghua.edu.cn/qhdai.html">Qionghai Dai</a>, <a href="http://www.liuyebin.com">Yebin Liu</a>
                </p>
                <p style="color: #EF7F27;">
                  ACM Transactions on Graphics <b>(Present in SIGGRAPH 2017)</b>
                </p>
                <p>
                  This paper proposes a real-time method that uses a single-view RGBD input to simultaneously reconstruct a casual scene with a detailed geometry model, surface albedo, per-frame non-rigid motion and per-frame low-frequency lighting, without requiring any template or motion priors. 
                </p>
                <p>
                    <a href="http://guokaiwen.com/monofvv.html">[Webpage]</a>&nbsp;
                    <a href="http://guokaiwen.com/main.pdf">[Paper]</a>&nbsp;
                    <a href="https://youtu.be/agIsYdrGzXc">[Youtube]</a>
                    <a href="http://guokaiwen.com/main_video_10th_edition_cq17.mp4">[Video]</a>&nbsp;
                </p>
              </div>
              <!-- End .project-info -->
            </div>
            <br><br> 
    </section>

    <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="experience">
      <div class="my-auto">
        <h2 class="mb-5">Experience</h2>

        <div class="resume-item d-flex flex-column flex-md-row mb-5">
          <div class="resume-content mr-auto">
            <h3 class="mb-0">Tsinghua University</h3>
            <div class="subheading mb-3">Visiting PhD Student</div>
            <div>Department of Automation, <a href = "http://media.au.tsinghua.edu.cn/people.jsp">BBNC Lab</a></div>
            <div><a href="http://www.liuyebin.com">Prof. Yebin Liu</a></div>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">November 2014 - Present</span>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row mb-5">
          <div class="resume-content mr-auto">
            <h3 class="mb-0">University of Southern California</h3>
            <div class="subheading mb-3">Graduate Research Associate</div>
            <div>Institute for Creative Technologies (ICT), <a href = "http://vgl.ict.usc.edu/">Vision & Graphics Lab</a></div>
            <div><a href = "http://hao-li.com/Hao_Li/Hao_Li_-_about_me.html">Prof. Hao Li</a></div>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">June 2017 - September 2017</span>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row mb-5">
          <div class="resume-content mr-auto">
            <h3 class="mb-0">Beihang University</h3>
            <div class="subheading mb-3">Master & PhD Candidate</div>
            <div>Precision Instrument and Machinery</div>
            <div>Prof. Jianhui Zhao</div>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">September 2012 - Present</span>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row">
          <div class="resume-content mr-auto">
            <h3 class="mb-0">Hefei University of Technolgy</h3>
            <div class="subheading mb-3">Bechelor</div>
            <div>Measurement and Control Technolgy</div>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">September 2008 - July 2012</span>
          </div>
        </div>

      </div>
    </section>

      <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="skills">
        <div class="my-auto">
          <h2 class="mb-5">Skills</h2>

          <div class="subheading mb-3">Programming Languages</div>
          <ul class="fa-ul mb-0">
            <li>
              <i class="fa-li fa fa-check"></i>
              C++</li>
            <li>
              <i class="fa-li fa fa-check"></i>
              CUDA C & Kernel Optimization</li>
            <li>
              <i class="fa-li fa fa-check"></i>
              GLSL</li>
          </ul>

          <br><div class="subheading mb-3">SoftWares</div>
          <ul class="fa-ul mb-0">
            <li>
              <i class="fa-li fa fa-check"></i>
              Autodesk Maya, Adobe Photoshop, Adobe AfterEffects, Adobe Premiere</li>
            <li>
              <i class="fa-li fa fa-check"></i>
              SolidWorks, AutoCAD, CAXA, Ansys</li>
          </ul>
        </div>
      </section>
    </div>

    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

    <!-- Custom scripts for this template -->
    <script src="js/resume.min.js"></script>

  </body>

</html>
